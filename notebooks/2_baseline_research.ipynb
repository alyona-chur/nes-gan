{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "JxklKZ0uR7ae",
      "metadata": {
        "id": "JxklKZ0uR7ae"
      },
      "source": [
        "# Initial Model Research (Baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R1AAVSbo1kJS",
      "metadata": {
        "id": "R1AAVSbo1kJS"
      },
      "source": [
        "## Google Colab or Jupyter Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8cVGg1D1fjd",
      "metadata": {
        "id": "m8cVGg1D1fjd"
      },
      "source": [
        "### Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WVL7KNHjR7GH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVL7KNHjR7GH",
        "outputId": "e1f3ce83-c841-42a1-be27-8c64e47f3798"
      },
      "outputs": [],
      "source": [
        "# Repo\n",
        "\n",
        "# GITHUB_PASSWORD = 'PASSWORD'\n",
        "# GIHUB_TOKEN = 'TOKEN'\n",
        "# GITHUB_USERNAME = 'USERNAME'\n",
        "# GUTHUB_EMAIL = 'EMAIL'\n",
        "# GITHUB_REPO = 'nesm-gan'\n",
        "# GITHUB_BRANCH = 'BRANCH'\n",
        "\n",
        "# !git config --global user.name {GITHUB_USERNAME}\n",
        "# !git config --global user.email {GUTHUB_EMAIL}\n",
        "# !git config --global user.password {GITHUB_PASSWORD}\n",
        "# !git clone https://{GIHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}\n",
        "\n",
        "# %cd {GITHUB_REPO}\n",
        "# !git checkout {GITHUB_BRANCH}\n",
        "# !git pull origin {GITHUB_BRANCH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-Ywmct2sTIM",
      "metadata": {
        "id": "c-Ywmct2sTIM"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "\n",
        "# from google.colab import drive  # To Log In\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !for f in \"/content/drive/My Drive/Colab/nesm_gan_data/\"*; \\\n",
        "# do ln -s \"$f\" \"/content/nesm-gan/data/$(basename \"$f\")\"; done\n",
        "# !for f in \"/content/drive/My Drive/Colab/nesm_gan_models/\"*; \\\n",
        "# do ln -s \"$f\" \"/content/nesm-gan/models/$(basename \"$f\")\"; done\n",
        "# !pip install dvc  # requirements.txt\n",
        "# !dvc pull\n",
        "\n",
        "# ROOT_DIR = '/content/nesm-gan/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mcO2z0DPZ8Er",
      "metadata": {
        "id": "mcO2z0DPZ8Er"
      },
      "source": [
        "### Jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E9WeucVbZ2Lp",
      "metadata": {
        "id": "E9WeucVbZ2Lp"
      },
      "outputs": [],
      "source": [
        "# Repo, data is stored locally\n",
        "\n",
        "# import os\n",
        "# import sys\n",
        "\n",
        "\n",
        "# ROOT_DIR = os.path.abspath('..')  # ROOT_DIR = Path(__file__).parents[1].resolve()\n",
        "# if ROOT_DIR not in sys.path:\n",
        "#     sys.path.append(ROOT_DIR)\n",
        "# sys.path.append(ROOT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70eSyQjXYYG4",
      "metadata": {
        "id": "70eSyQjXYYG4"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdaa373",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6fdaa373",
        "outputId": "3af4c6ba-6d1c-4190-bcc9-2df7b74ed433"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow\n",
        "!pip install pyngrok\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "import numpy as np\n",
        "# from pyngrok import ngrok\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# Random\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_SEED = 13\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Configuration\n",
        "NOISE_VECTOR_LEN = 100\n",
        "\n",
        "# Train data\n",
        "DATA_PATH = ROOT_DIR / Path('data/nesmdb24_seprsco_train_ready')\n",
        "MODELS_PATH = ROOT_DIR / Path('data/models')\n",
        "SAMPLE_LEN = 256 # 128 = 4-5sec\n",
        "ROWS_CNT = 8\n",
        "\n",
        "for file in DATA_PATH.iterdir():\n",
        "    song = np.load(file)\n",
        "    print(song.shape)\n",
        "    plt.imshow(song, cmap='gray')\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yoaho5TH5WTd",
      "metadata": {
        "id": "Yoaho5TH5WTd"
      },
      "source": [
        "#### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VqAzBdnz7giE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "VqAzBdnz7giE",
        "outputId": "2433749b-55cf-42c1-cba1-60d2f646805c"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_len: int):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Transform input noise vector to a suitable shape for deconvolutional layers.\n",
        "        # Layer input: [batch_size, noise_len]\n",
        "        # Layer output: [batch_size, 128*8*8] (will be reshaped to [batch_size, 128, 8, 8])\n",
        "        self.fc = nn.Linear(noise_len, 128 * 8 * 8, bias=False)\n",
        "\n",
        "        # First deconvolution layer increases spatial dimensions.\n",
        "        # Layer input: [batch_size, 128, 8, 8]\n",
        "        # Layer output: [batch_size, 64, 16, 16]\n",
        "        self.conv1 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Batch normalization stabilizes training.\n",
        "        # Layer input: [batch_size, 64, 16, 16]\n",
        "        # Layer output: [batch_size, 64, 16, 16]\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Second deconvolution layer further increases spatial dimensions.\n",
        "        # Layer input: [batch_size, 64, 16, 16]\n",
        "        # Layer output: [batch_size, 32, 32, 32]\n",
        "        self.conv2 = nn.ConvTranspose2d(64, 32, 4, stride=1, padding=1, bias=False)\n",
        "\n",
        "        # Another batch normalization layer.\n",
        "        # Layer input: [batch_size, 32, 32, 32]\n",
        "        # Layer output: [batch_size, 32, 32, 32]\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Final deconvolution layer to produce the output image.\n",
        "        # Layer input: [batch_size, 32, 32, 32]\n",
        "        # Layer output: [batch_size, 1, 32, 32]\n",
        "        self.conv3 = nn.ConvTranspose2d(32, 1, 2, stride=2, padding=1, bias=True)\n",
        "        # self.conv3 = nn.ConvTranspose2d(32, 1, 4, stride=2, padding=2, dilation=1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 128, 8, 8)  # Reshape to [batch_size, 128, 8, 8]\n",
        "        x = F.leaky_relu(self.batchnorm1(self.conv1(x)), 0.2)  # LeakyReLU for non-linearity\n",
        "        x = F.leaky_relu(self.batchnorm2(self.conv2(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv3(x))  # Final activation to get output in [0, 1]\n",
        "        return x\n",
        "\n",
        "\n",
        "generator = Generator(NOISE_VECTOR_LEN)\n",
        "noise = torch.randn(1, NOISE_VECTOR_LEN)\n",
        "with torch.no_grad():\n",
        "    generated_image = generator(noise)\n",
        "    print(generated_image.shape)\n",
        "\n",
        "    image = generated_image[0].permute(1, 2, 0).numpy()\n",
        "    print(image.shape)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LYA_T8tC8d5l",
      "metadata": {
        "id": "LYA_T8tC8d5l"
      },
      "source": [
        "#### Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3KXxwQT08b9X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KXxwQT08b9X",
        "outputId": "8f94b396-5b29-45c1-8fed-8aa7f0b681e3"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Convolution layer to downsample the image.\n",
        "        # Layer input: [batch_size, 1, 32, 32] / [batch_size, channels, height, width]\n",
        "        # Layer output: [batch_size, 32, 16, 16]\n",
        "        self.conv1 = nn.Conv2d(1, 32, 4, stride=2, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Second convolution layer to further downsample.\n",
        "        # Layer input: [batch_size, 32, 16, 16]\n",
        "        # Layer output: [batch_size, 64, 8, 8]\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Third convolution layer.\n",
        "        # Layer input: [batch_size, 64, 8, 8]\n",
        "        # Layer output: [batch_size, 128, 4, 4]\n",
        "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Fully connected layer to output a single value (real/fake probability).\n",
        "        # Layer input: [batch_size, 128*4*4]\n",
        "        # Layer output: [batch_size, 1]\n",
        "        self.fc = nn.Linear(128 * 4 * 4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.batchnorm1(self.conv1(x)), 0.2)\n",
        "        x = F.leaky_relu(self.batchnorm2(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.batchnorm3(self.conv3(x)), 0.2)\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = torch.sigmoid(self.fc(x))  # Sigmoid activation to get a probability\n",
        "        return x\n",
        "\n",
        "\n",
        "discriminator = Discriminator()\n",
        "with torch.no_grad():\n",
        "    decision = discriminator(generated_image)\n",
        "    print(decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rE20r6PEYovr",
      "metadata": {
        "id": "rE20r6PEYovr"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8rnWrXuhYnuz",
      "metadata": {
        "id": "8rnWrXuhYnuz"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path):\n",
        "        self.data_dir = data_dir\n",
        "        self.file_list = list(data_dir.iterdir())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        file_path = self.file_list[idx]\n",
        "        image = np.load(file_path)\n",
        "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JP83kCShTak6",
      "metadata": {
        "id": "JP83kCShTak6"
      },
      "source": [
        "## Training\n",
        "NESMGAN Experiment 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1wKXRBCLAugP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wKXRBCLAugP",
        "outputId": "457e87b3-ed70-4e26-d5bb-f231b475127b"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4wAs_F9kg_hW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAs_F9kg_hW",
        "outputId": "c3c2dcc8-9dca-43e6-b81c-8afc41a8ce06"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "EXPERIMENT_NAME = '0'\n",
        "BATCH_SIZE = 256\n",
        "LR = 0.0002\n",
        "EPOCHS = 1000\n",
        "\n",
        "\n",
        "def train(generator: nn.Module,\n",
        "          discriminator: nn.Module,\n",
        "          optimizer_G: optim.Adam,\n",
        "          optimizer_D: optim.Adam,\n",
        "          loss: nn.Module,\n",
        "          dataloader: torch.utils.data.DataLoader):\n",
        "    for epoch in range(EPOCHS):\n",
        "        for batch_idx, real_images in enumerate(dataloader):\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Generate fake images using random noise\n",
        "            noise = torch.randn(batch_size, NOISE_VECTOR_LEN)\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            real_labels = torch.ones(batch_size, 1)\n",
        "            fake_labels = torch.zeros(batch_size, 1)\n",
        "            # print(f'{real_images.shape=}, {fake_labels.shape=}')\n",
        "\n",
        "            # Detach fake_images to avoid generator gradients\n",
        "            real_outputs = discriminator(real_images)\n",
        "            fake_outputs = discriminator(fake_images.detach())\n",
        "            # print(f'{real_outputs.shape=}, {fake_outputs.shape=}')\n",
        "\n",
        "            d_loss_real = loss(real_outputs, real_labels)\n",
        "            d_loss_fake = loss(fake_outputs, fake_labels)\n",
        "            d_loss = d_loss_real + d_loss_fake  # / 2.0\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_G.zero_grad()\n",
        "            noise = torch.randn(batch_size, NOISE_VECTOR_LEN)\n",
        "            fake_images = generator(noise)\n",
        "            fake_outputs = discriminator(fake_images)\n",
        "\n",
        "            # Generator wants discriminator to output 1 for fakes\n",
        "            g_loss = loss(fake_outputs, real_labels)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            mlflow.log_metric(\"D Loss\", d_loss.item(), step=epoch * len(dataloader) + batch_idx)\n",
        "            mlflow.log_metric(\"G Loss\", g_loss.item(), step=epoch * len(dataloader) + batch_idx)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch [{epoch}/{EPOCHS}], Batch [{batch_idx}/{len(dataloader)}], '\n",
        "                    f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 or epoch + 1 == EPOCHS:\n",
        "            model_save_path = \\\n",
        "                f'{MODELS_PATH}/{EXPERIMENT_NAME}_model_checkpoints/epoch_{epoch + 1}'\n",
        "            model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(generator.state_dict(),\n",
        "                        model_save_path / 'generator_state_dict.pth')\n",
        "            torch.save(discriminator.state_dict(),\n",
        "                        model_save_path / 'discriminator_state_dict.pth')\n",
        "\n",
        "\n",
        "dataset = CustomDataset(DATA_PATH)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "generator = Generator(NOISE_VECTOR_LEN)\n",
        "discriminator = Discriminator()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=LR)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=LR)\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "\n",
        "# Training\n",
        "mlflow.set_experiment(f'NESMGAN Experiment {EXPERIMENT_NAME}')\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
        "    mlflow.log_param(\"learning_rate\", LR)\n",
        "    mlflow.log_param(\"epochs\", EPOCHS)\n",
        "\n",
        "    train(generator, discriminator, optimizer_G, optimizer_D, loss, dataloader)\n",
        "\n",
        "    mlflow.pytorch.log_model(generator, \"generator\")\n",
        "    mlflow.pytorch.log_model(discriminator, \"discriminator\")\n",
        "\n",
        "\n",
        "# Generate and visualize images after training\n",
        "num_images_to_show = 5\n",
        "noise = torch.randn(num_images_to_show, NOISE_VECTOR_LEN)\n",
        "generated_images = generator(noise).detach().cpu()\n",
        "\n",
        "fig, axs = plt.subplots(1, num_images_to_show, figsize=(12, 3))\n",
        "\n",
        "for i in range(num_images_to_show):\n",
        "    axs[i].imshow(generated_images[i].squeeze().numpy(), cmap='gray')\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dJ9upSTI7QFs",
      "metadata": {
        "id": "dJ9upSTI7QFs"
      },
      "outputs": [],
      "source": [
        "# NGROK_AUTH_TOKEN = 'NGROK_AUTH_TOKEN'\n",
        "# ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "# get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "# public_url = ngrok.connect(port=5000)\n",
        "# print(f'MLFlow Tracking UI: {public_url}')\n",
        "# !mlflow ui"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mcO2z0DPZ8Er"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
